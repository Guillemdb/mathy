{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This file is generated from a Mathy (https://mathy.ai) code example.\n",
    "!pip install mathy --upgrade\n",
    "import tensorflow as tf\n",
    "\n",
    "from mathy import envs\n",
    "from mathy.agents.base_config import BaseConfig\n",
    "from mathy.agents.policy_value_model import PolicyValueModel, get_or_create_policy_model\n",
    "from mathy.env import MathyEnv\n",
    "from mathy.state import MathyObservation, observations_to_window\n",
    "\n",
    "args = BaseConfig()\n",
    "env: MathyEnv = envs.PolySimplify()\n",
    "observation: MathyObservation = env.state_to_observation(\n",
    "    env.get_initial_state()[0], rnn_size=args.lstm_units\n",
    ")\n",
    "model = get_or_create_policy_model(args, predictions=env.action_size)\n",
    "inputs = observations_to_window([observation]).to_inputs()\n",
    "# predict_next only returns a policy for the last observation\n",
    "# in the sequence, and applies masking and softmax to the output\n",
    "policy, value, masked = model.predict([inputs])\n",
    "\n",
    "# The policy is a 2D array of size (observations, num_nodes, actions)\n",
    "assert policy.shape == (1, len(observation.nodes), env.action_size,)\n",
    "# There should be one floating point output Value\n",
    "assert isinstance(float(value), float)\n",
    "\n",
    "# Save/Load the model\n",
    "model = model.from_bytes(model.to_bytes())\n",
    "\n",
    "# Forward pass\n",
    "policy, value, masked = model.predict([inputs])\n",
    "\n",
    "assert policy.shape == (1, len(observation.nodes), env.action_size,)\n",
    "assert isinstance(float(value), float)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
