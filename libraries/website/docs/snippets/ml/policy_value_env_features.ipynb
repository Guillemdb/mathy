{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This file is generated from a mathy documentation code snippet.\n",
    "!pip install mathy\n",
    "from mathy import envs\n",
    "from mathy.agents.base_config import BaseConfig\n",
    "from mathy.agents.policy_value_model import PolicyValueModel\n",
    "from mathy.env import MathyEnv\n",
    "from mathy.state import MathyObservation, observations_to_window\n",
    "\n",
    "args = BaseConfig(use_env_features=True)\n",
    "env: MathyEnv = envs.PolySimplify()\n",
    "observation: MathyObservation = env.state_to_observation(\n",
    "    env.get_initial_state()[0], rnn_size=args.lstm_units\n",
    ")\n",
    "model = PolicyValueModel(args, predictions=env.action_size)\n",
    "inputs = observations_to_window([observation]).to_inputs()\n",
    "# predict_next only returns a policy for the last observation\n",
    "# in the sequence, and applies masking and softmax to the output\n",
    "policy, value = model.predict_next(inputs)\n",
    "\n",
    "# The policy is a 1D array of size (actions * num_nodes)\n",
    "assert policy.shape.rank == 1\n",
    "assert policy.shape == (env.action_size * len(observation.nodes),)\n",
    "\n",
    "# There should be one floating point output Value\n",
    "assert value.shape.rank == 0\n",
    "assert isinstance(float(value.numpy()), float)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
