{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This file is generated from a Mathy (https://mathy.ai) code example.\n",
    "!pip install mathy --upgrade\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from mathy import envs\n",
    "from mathy.agents.base_config import BaseConfig\n",
    "from mathy.agents.embedding import MathyEmbedding\n",
    "from mathy.env import MathyEnv\n",
    "from mathy.state import MathyEnvState, MathyObservation, observations_to_window\n",
    "from thinc.api import TensorFlowWrapper\n",
    "from thinc.layers import (\n",
    "    Embed,\n",
    "    Linear,\n",
    "    MeanPool,\n",
    "    ReLu,\n",
    "    Softmax,\n",
    "    chain,\n",
    "    list2ragged,\n",
    "    with_array,\n",
    "    with_list,\n",
    ")\n",
    "from thinc.model import Model\n",
    "from thinc.shims.tensorflow import TensorFlowShim\n",
    "from thinc.types import Array, Array1d, Array2d, ArrayNd\n",
    "\n",
    "# Mathy env setup and initial observations\n",
    "args = BaseConfig()\n",
    "env: MathyEnv = envs.PolySimplify()\n",
    "state: MathyEnvState = env.get_initial_state()[0]\n",
    "observation: MathyObservation = env.state_to_observation(\n",
    "    state, rnn_size=args.lstm_units\n",
    ")\n",
    "window = observations_to_window([observation, observation])\n",
    "inputs = window.to_inputs()\n",
    "\n",
    "X = [inputs]  # TODO: why do I need to wrap inputs for the tf wrapper?\n",
    "input_shape = window.to_input_shapes()\n",
    "embeddings = TensorFlowWrapper(MathyEmbedding(args), input_shape=input_shape)\n",
    "embeddings.initialize([inputs])\n",
    "\n",
    "embed_Y = embeddings.predict([inputs])\n",
    "# Shape = (2, 23, 128) = (num_observations, padded_sequence_len, vector_width)\n",
    "\n",
    "# The policy head is a softmax(actions) for each node in the sequence.\n",
    "policy_head = chain(embeddings, Softmax(6))\n",
    "policy_head.initialize([inputs])\n",
    "policy_Y = policy_head.predict([inputs])\n",
    "# Shape (desired) = (2, 23, 6)\n",
    "\n",
    "# The value head is normally a linear transformation from the\n",
    "# output embedding layer's RNN state. I haven't tried mixing\n",
    "# that tensor in here. TODO: try that\n",
    "value_head = chain(embeddings, MeanPool(), Linear(1))\n",
    "value_head.initialize([inputs])\n",
    "value_Y = value_head.predict([inputs])\n",
    "# Shape (desired) = (2, 1)\n",
    "\n",
    "# Combined [policy_head, value_head] outputs without invoking embeddings twice?\n",
    "model: Model[ArrayNd, Tuple[Array2d, Array1d]] = ...\n",
    "\n",
    "model.initialize([inputs])\n",
    "\n",
    "Y = model.predict([inputs])\n",
    "model.to_disk(f\"training/model\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
